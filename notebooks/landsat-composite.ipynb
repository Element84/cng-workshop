{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5071afec",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Landsat Compositing\n",
    "\n",
    "This notebook explores creating composites (i.e., mosaics) from the Landsat Collection 2 data using:\n",
    "\n",
    "- [Landsat Collection 2 STAC API](https://landsatlook.usgs.gov/stac-server), a catalog of Landsat data\n",
    "- [pystac-client](https://pystac-client.readthedocs.io/) for searching and access data\n",
    "- [OpenDataCube](https://www.opendatacube.org/) and [odc-stac](https://odc-stac.readthedocs.io/) for loading STAC assets and representing geospatial data as XArrays\n",
    "- [XArray](http://xarray.pydata.org/en/stable/), [pandas](https://pandas.pydata.org/) [geopandas](https://geopandas.org/), [odc-tools](https://github.com/opendatacube/odc-tools), and [deafrica_tools](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks/tree/main/Tools) for manipulating data\n",
    "- [Dask](https://dask.org/) for performing parallel, distributed computing\n",
    "- [Coiled.io](https://coiled.io/), a service for hosting Dask clusters\n",
    "- [hvplot](https://hvplot.holoviz.org/) for visualization\n",
    "\n",
    "Shown will be how to find data for an area of interest, explore the resulting metadata, perform calculations, and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9a879-a383-419c-88d8-0536f84ea3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize holoviews\n",
    "\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "\n",
    "import geopandas as gpd\n",
    "import hvplot.pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "id": "48d468a5-aca4-4f73-99e4-c2e9727091e5",
   "metadata": {},
   "source": [
    "# notebook init\n",
    "\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "\n",
    "from copy import deepcopy\n",
    "import geopandas as gpd\n",
    "import hvplot.pandas\n",
    "import pandas as pd\n",
    "import pystac\n",
    "from shapely.geometry import shape\n",
    "import os\n",
    "\n",
    "# convert a list of STAC Items into a GeoDataFrame\n",
    "def items_to_geodataframe(items):\n",
    "    _items = []\n",
    "    for i in items:\n",
    "        _i = deepcopy(i)\n",
    "        _i['geometry'] = shape(_i['geometry'])\n",
    "        _items.append(_i)\n",
    "    gdf = gpd.GeoDataFrame(pd.json_normalize(_items))\n",
    "    for field in ['properties.datetime', 'properties.created', 'properties.updated']:\n",
    "        if field in gdf:\n",
    "            gdf[field] = pd.to_datetime(gdf[field])\n",
    "    gdf.set_index('properties.datetime', inplace=True)\n",
    "    return gdf\n",
    "\n",
    "def update_landsat_items(items_dict):\n",
    "    # update URLs to use s3\n",
    "    for item in items_dict:\n",
    "        for a in item['assets']:\n",
    "            if 'alternate' in item['assets'][a] and 's3' in item['assets'][a]['alternate']:\n",
    "                item['assets'][a]['href'] = item['assets'][a]['alternate']['s3']['href']\n",
    "            item['assets'][a]['href'] = item['assets'][a]['href'].replace('usgs-landsat-ard', 'usgs-landsat')\n",
    "\n",
    "import yaml\n",
    "\n",
    "def read_yaml(filename):\n",
    "    with open(filename, \"r\") as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "            \n",
    "            \n",
    "# set pystac_client logger to DEBUG to see API calls\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger('pystac_client')\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f713f7-7197-4d5a-b140-e721e361b02f",
   "metadata": {},
   "source": [
    "# Choose Area of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa9503f-e81b-47f8-91a8-d0c20a3d0ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AOIs available\n",
    "\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(glob(\"../aois/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dc1844-d812-406c-a211-c1f737a5818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the GeoJSON file and create a map\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "aoi_fname = \"../aois/malawi.geojson\"\n",
    "\n",
    "aoi = json.loads(Path(aoi_fname).read_text())\n",
    "\n",
    "# use folium to display vectors\n",
    "# Several folium basemap tiles are available:\n",
    "#   - OpenStreetMap\n",
    "#   - Stamen Terrain\n",
    "#   - Stamen Toner\n",
    "#   - Stamen Watercolor\n",
    "#   - CartoDB positron\n",
    "#   - CartoDB dark_matter\n",
    "\n",
    "import folium\n",
    "\n",
    "map = folium.Map(tiles='OpenStreetMap')\n",
    "\n",
    "# add vector to map, as transparent polygon\n",
    "folium.GeoJson(aoi, style_function = lambda x: {'fillColor': '#00000000'}).add_to(map)\n",
    "\n",
    "# fit the map to the bounds of the data\n",
    "lons = [x[0] for x in aoi[\"geometry\"][\"coordinates\"][0]]\n",
    "lats = [x[1] for x in aoi[\"geometry\"][\"coordinates\"][0]]\n",
    "map.fit_bounds([(min(lats), min(lons)), (max(lats), max(lons))])\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f100b1b",
   "metadata": {},
   "source": [
    "# Data Discovery\n",
    "\n",
    "Use pystac-client to find data in the Landsat STAC API. First, fetch the collection of interest: Landsat Collection 2, Level 2 Surface Reflectance (landsat-c2l2-sr) and print the assets that are available. Then make a query with an AOI, date range, and search parameters.\n",
    "\n",
    "The Landsat Items are all the asset URLS are updated to use the provided s3 URLs which can be used for direct access rather than the default https URLs. This is because the alternate extension is not yet supported in PySTAC, when it is there will be an easier way to specify which alternate URL, if any, to use for the assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b61c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystac_client import Client\n",
    "\n",
    "api = Client.open(\"https://landsatlook.usgs.gov/stac-server\")\n",
    "\n",
    "collection = api.get_collection(\"landsat-c2l2-sr\")\n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee51c518-a899-4b10-bede-07ac4477aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# search the API\n",
    "\n",
    "query = api.search(\n",
    "    collections=[collection.id],\n",
    "    intersects=aoi['geometry'],\n",
    "    datetime=\"2021-06-01/2021-08-31\",\n",
    "    limit=100,\n",
    "    query = [\n",
    "        \"platform=LANDSAT_8\",\n",
    "        \"eo:cloud_cover<80\"\n",
    "    ]\n",
    ")\n",
    "item_collection = query.item_collection()\n",
    "\n",
    "print(f\"Found: {len(item_collection):d} STAC Items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f480fb-dfeb-47e4-b6b2-92b4e12bdb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# display the map with footprints\n",
    "\n",
    "# view footprints\n",
    "style = {\n",
    "    'fillColor': '#00000000', # transparent\n",
    "    'color': '#fc0f03',       # red\n",
    "    'weight': 1\n",
    "}\n",
    "\n",
    "for item in item_collection:\n",
    "    folium.GeoJson(item.to_dict(), style_function=lambda x: style).add_to(map)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308d8fa9-7e5c-4b37-bbdc-0ee184195ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update Item assets to use the alternate s3 URL\n",
    "\n",
    "def update_landsat_items(items_dict):\n",
    "    # update URLs to use s3\n",
    "    for item in items_dict:\n",
    "        #print(item)\n",
    "        for a in item['assets']:\n",
    "            if 'alternate' in item['assets'][a] and 's3' in item['assets'][a]['alternate']:\n",
    "                item['assets'][a]['href'] = item['assets'][a]['alternate']['s3']['href']\n",
    "            item['assets'][a]['href'] = item['assets'][a]['href'].replace('usgs-landsat-ard', 'usgs-landsat')\n",
    "    return items_dict\n",
    "\n",
    "items_dict = update_landsat_items(item_collection.to_dict()['features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f258702",
   "metadata": {},
   "source": [
    "# OpenDataCube\n",
    "\n",
    "Now we'll turn the set of scenes into a virtual datacube. None of the data will actually be read yet. A PySTAC ItemCollection is created from the found STAC Items, with parameters such as bands of interest and chunk size. The configuration string (`cfg`) is for providing info on the cloud mask values, which while in the the STAC Items, is not currently supported by ogc-stac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68afc592-7ddc-4b8b-bb18-76fe27ba83da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in additional Landsat config info\n",
    "\n",
    "import yaml\n",
    "\n",
    "def read_yaml(filename):\n",
    "    with open(filename, \"r\") as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "\n",
    "cfg = read_yaml('landsat.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583cd3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from odc.stac import stac_load\n",
    "\n",
    "# default to CRS and resolution from first Item\n",
    "from pystac.extensions.projection import ProjectionExtension\n",
    "from pyproj import CRS\n",
    "\n",
    "proj = ProjectionExtension.ext(item_collection[0])\n",
    "output_crs = CRS.from_epsg(proj.epsg)\n",
    "resolution = min(proj.transform[4], proj.transform[0])\n",
    "\n",
    "dc = stac_load(item_collection,\n",
    "               geopolygon=aoi['geometry'],\n",
    "               chunks={\"x\": 2048, \"y\": 2048},\n",
    "               output_crs=output_crs,\n",
    "               resolution=resolution,\n",
    "               groupby='solar_day',\n",
    "               stac_cfg=cfg)\n",
    "dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c504a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from odc.algo import erase_bad\n",
    "from datacube.utils import masking\n",
    "\n",
    "dc['qa_pixel'].attrs['flags_definition'] = cfg[collection.id]['assets']['qa_pixel']['flags_definition']\n",
    "\n",
    "# remove negative pixels - a pixel is invalid if any of the band is smaller than masking_scale\n",
    "#valid = (dc[self.bands] > (-1.0 * self.offset/self.scale)).to_array(dim='band').all(dim='band')\n",
    "\n",
    "mask_band = dc['qa_pixel']\n",
    "dc = dc.drop_vars(['qa_pixel'])\n",
    "\n",
    "flags_def = masking.get_flags_def(mask_band)\n",
    "\n",
    "# set cloud_mask - True=cloud, False=non-cloud\n",
    "mask, _ = masking.create_mask_value(flags_def, cloud=\"high_confidence\", cirrus=\"high_confidence\",)\n",
    "cloud_mask = (mask_band & mask) != 0\n",
    "\n",
    "# set no_data bitmask - True=data, False=no-data\n",
    "nodata_mask, _ = masking.create_mask_value(flags_def, nodata=False)\n",
    "keeps = (mask_band & nodata_mask) == 0\n",
    "\n",
    "dc = erase_bad(dc, where=cloud_mask)\n",
    "dc['cloud_mask'] = cloud_mask\n",
    "\n",
    "dc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b11cdb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Start Dask Client\n",
    "\n",
    "Start either a local Dask, or use [coiled.io](coiled.io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6332c88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# start Dask cluster using coiled\n",
    "\n",
    "import coiled\n",
    "from dask.distributed import Client\n",
    "\n",
    "# start dask cluster on coiled.io\n",
    "cluster = coiled.Cluster(\n",
    "    n_workers=10,\n",
    "    software=\"cng-workshop\",\n",
    "    backend_options={\"region\": \"us-west-2\"},\n",
    "    environ={\"GDAL_DISABLE_READDIR_ON_OPEN\": \"YES\", \"AWS_REQUEST_PAYER\": \"requester\"}\n",
    ")\n",
    "client = Client(cluster)\n",
    "\n",
    "print('Dashboard:', client.dashboard_link)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e81b48",
   "metadata": {},
   "source": [
    "# Visualize\n",
    "\n",
    "Look at the individual time scenes and create an animated GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3159d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from dask.distributed import wait\n",
    "\n",
    "# persist the read data on Dask cluster\n",
    "dc = client.persist(dc)\n",
    "_ = wait(dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50e7df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "# fetch all the values from dask\n",
    "#dc_local = dc.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9d1797",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from deafrica_tools.plotting import rgb\n",
    "\n",
    "rgb(dc, bands=['red', 'green', 'blue'], col='time') #, percentile_stretch=[0.01, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87c76aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from deafrica_tools.plotting import xr_animation\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "# Produce time series animation of red, green and blue bands\n",
    "xr_animation(ds=dc,\n",
    "             bands=['red', 'green', 'blue'],\n",
    "             output_path='landsat-timeseries.gif',\n",
    "             percentile_stretch=(0.1, 0.99),\n",
    "             interval=600,\n",
    "             width_pixels=800)\n",
    "\n",
    "# Plot animated gif\n",
    "plt.close()\n",
    "Image(filename='landsat-timeseries.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f24c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# persist the read data on Dask cluster\n",
    "dc = client.persist(dc)\n",
    "_ = wait(dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8b6555",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from deafrica_tools.plotting import rgb\n",
    "\n",
    "rgb(dc, bands=['red', 'green', 'blue'], col='time') #, percentile_stretch=[0.01, 0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a7b7b2",
   "metadata": {},
   "source": [
    "# Basic Composite\n",
    "\n",
    "Generate basic composites using simple statistics: mean, median, min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59a1a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from odc.algo import to_float\n",
    "\n",
    "dc_float = to_float(dc, dtype='float32')\n",
    "\n",
    "rgb(dc_float.mean('time'), bands=['red', 'green', 'blue'], size=20, percentile_stretch=(0.02, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f9e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb(dc_float.median('time'), bands=['red', 'green', 'blue'], size=20, percentile_stretch=(0.02, 0.92))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8920daa1",
   "metadata": {},
   "source": [
    "# Percentile Composite\n",
    "\n",
    "The datacube currently contains complete Items, we want to clip these to our geometry of interest. We will then also create an RGB datacube representation, and generate an NDVI datacube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c353a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from odc.algo import xr_quantile\n",
    "\n",
    "stats = xr_quantile(dc, [0.2, 0.8], 0.0)\n",
    "\n",
    "stats = stats.compute()\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aaf0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rgb(stats.sel(quantile=0.2), bands=['red', 'green', 'blue'], size=12, percentile_stretch=[0.02, 0.98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19842218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.xarray\n",
    "\n",
    "from odc.algo import to_rgba\n",
    "\n",
    "epsg = int(dc.attrs['crs'].split(':')[-1])\n",
    "\n",
    "vis = to_rgba(stats.sel(quantile=0.8), clamp=(1000, 30000), bands=['red', 'green', 'blue'])\n",
    "vis.hvplot.rgb(x='x', y='y', bands='band', crs=epsg, tiles='OSM', frame_width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb97978a",
   "metadata": {},
   "source": [
    "# Shutdown cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.shutdown()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2e19bf-e0eb-456e-84cb-b3c078a6af37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
